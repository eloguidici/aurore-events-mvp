# ¬øC√≥mo Funciona el Sistema? - Explicaci√≥n Completa

## üéØ Visi√≥n General

El sistema tiene **dos caminos separados**:

1. **Camino R√°pido (Request Path)**: Recibe eventos y los encola ‚Üí respuesta inmediata
2. **Camino de Persistencia (Worker)**: Procesa eventos en lotes y los guarda en la base de datos

Esto permite **alta velocidad** en la ingesta sin bloquear el sistema.

---

## üì• PASO 1: Llega un Evento (POST /events)

### Ejemplo de Request:
```bash
POST http://localhost:3000/events
Content-Type: application/json

{
  "timestamp": "2024-01-15T10:30:00Z",
  "service": "auth-service",
  "message": "User login successful",
  "metadata": {
    "user_id": "12345"
  }
}
```

### ¬øQu√© pasa en el c√≥digo?

**Archivo:** `src/events/events.controller.ts` - m√©todo `ingestEvent()`

```typescript
@Post('events')
async ingestEvent(@Body() createEventDto: CreateEventDto) {
  // 1. VALIDACI√ìN AUTOM√ÅTICA (NestJS ValidationPipe)
  //    Si el evento es inv√°lido ‚Üí 400 Bad Request (NUNCA entra al buffer)
  
  // 2. VERIFICAR SI EL BUFFER EST√Å LLENO
  if (this.eventBufferService.isFull()) {
    return 429 Too Many Requests  // Backpressure
  }
  
  // 3. ENRIQUECER EL EVENTO (agregar ID y timestamp de ingesta)
  const enrichedEvent = {
    eventId: "evt_abc123",
    timestamp: "2024-01-15T10:30:00Z",
    service: "auth-service",
    message: "User login successful",
    metadata: {...},
    ingestedAt: "2024-01-15T10:30:00.123Z"
  }
  
  // 4. ENCOLAR EN EL BUFFER (operaci√≥n O(1), no bloquea)
  this.eventBufferService.enqueue(enrichedEvent);
  
  // 5. RESPONDER INMEDIATAMENTE (202 Accepted)
  return {
    status: "accepted",
    event_id: "evt_abc123",
    queued_at: "2024-01-15T10:30:00.123Z"
  }
}
```

**Tiempo total:** < 5 milisegundos ‚ö°

---

## ‚úÖ PASO 2: Validaci√≥n en el Borde

### ¬øQu√© se valida?

**Archivo:** `src/events/dto/create-event.dto.ts`

```typescript
export class CreateEventDto {
  @IsString()
  @IsNotEmpty()
  @IsParseableTimestamp()  // Debe ser fecha v√°lida (ISO o epoch)
  timestamp: string;

  @IsString()
  @IsNotEmpty()
  @MaxLength(100)  // M√°ximo 100 caracteres
  service: string;

  @IsString()
  @IsNotEmpty()
  @MaxLength(2000)  // M√°ximo 2000 caracteres
  message: string;

  @IsOptional()
  @IsObject()
  @IsMetadataSizeValid()  // M√°ximo 16KB cuando se stringifica
  metadata?: Record<string, any>;
}
```

### Si el evento es inv√°lido:

```json
// Respuesta 400 Bad Request
{
  "status": "error",
  "message": "Invalid event schema",
  "errorCode": "INVALID_EVENT",
  "errors": [
    {
      "field": "timestamp",
      "constraints": {
        "isParseableTimestamp": "timestamp must be a parseable date"
      }
    }
  ]
}
```

**Importante:** El evento **NUNCA entra al buffer**. Se rechaza en el borde.

---

## üì¶ PASO 3: Buffer en Memoria

### ¬øQu√© es el buffer?

**Archivo:** `src/events/services/event-buffer.service.ts`

```typescript
export class EventBufferService {
  private buffer: EnrichedEvent[] = [];  // Array en memoria
  private maxSize = 10000;  // Capacidad m√°xima (configurable)
  
  enqueue(event: EnrichedEvent): boolean {
    if (this.buffer.length >= this.maxSize) {
      return false;  // Buffer lleno
    }
    
    this.buffer.push(event);  // Agregar al final (O(1))
    return true;
  }
  
  drainBatch(batchSize: number): EnrichedEvent[] {
    // Sacar hasta 'batchSize' eventos del inicio
    const batch = [];
    for (let i = 0; i < batchSize && this.buffer.length > 0; i++) {
      batch.push(this.buffer.shift());  // FIFO (First In, First Out)
    }
    return batch;
  }
}
```

### Visualizaci√≥n:

```
Buffer (Array en memoria):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ [event1] [event2] [event3] ...      ‚îÇ  ‚Üê Eventos esperando
‚îÇ                                     ‚îÇ
‚îÇ Capacidad: 10,000 eventos          ‚îÇ
‚îÇ Actual: 1,250 eventos              ‚îÇ
‚îÇ Utilizaci√≥n: 12.5%                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### ¬øQu√© pasa si el buffer se llena?

```typescript
if (this.eventBufferService.isFull()) {
  // Respuesta 429 Too Many Requests
  throw new HttpException({
    status: 'rate_limited',
    message: 'Buffer is full. Please retry in a few seconds.',
    retry_after: 5,
    errorCode: 'BUFFER_SATURATED'
  }, 429);
}
```

Esto es **backpressure**: el sistema se protege rechazando eventos cuando est√° saturado.

---

## ‚öôÔ∏è PASO 4: Worker de Procesamiento por Lotes

### ¬øC√≥mo funciona el worker?

**Archivo:** `src/batch-worker/batch-worker.service.ts`

El worker se ejecuta **cada 1 segundo** (configurable) y hace lo siguiente:

```typescript
// Se ejecuta autom√°ticamente cada 1 segundo
private async processBatch() {
  // 1. DRENAR EL BUFFER (sacar hasta 500 eventos)
  const batch = this.eventBufferService.drainBatch(500);
  
  if (batch.length === 0) {
    return;  // Buffer vac√≠o, no hay nada que hacer
  }
  
  // 2. VALIDAR EVENTOS (validaci√≥n profunda)
  const { validEvents, invalidEvents } = this.validateBatch(batch);
  
  // 3. INSERTAR A LA BASE DE DATOS (lote completo)
  if (validEvents.length > 0) {
    const { successful, failed } = await this.eventsService.batchInsert(validEvents);
    
    // 4. REINTENTAR EVENTOS FALLIDOS (con exponential backoff)
    if (failed > 0) {
      this.retryFailedEvents(failedEvents);
    }
  }
}
```

### Visualizaci√≥n del Proceso:

```
Cada 1 segundo:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Worker despierta                         ‚îÇ
‚îÇ   ‚Üì                                      ‚îÇ
‚îÇ Drena buffer: [500 eventos]              ‚îÇ
‚îÇ   ‚Üì                                      ‚îÇ
‚îÇ Valida: 495 v√°lidos, 5 inv√°lidos        ‚îÇ
‚îÇ   ‚Üì                                      ‚îÇ
‚îÇ Inserta en DB: 495 eventos               ‚îÇ
‚îÇ   ‚Üì                                      ‚îÇ
‚îÇ Si fallan: Reintenta con backoff        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíæ PASO 5: Persistencia en Base de Datos

### ¬øC√≥mo se guardan los eventos?

**Archivo:** `src/events/services/events.service.ts`

```typescript
async batchInsert(events: CreateEventDto[]) {
  try {
    // TRANSACCI√ìN AT√ìMICA (todo o nada)
    await this.eventRepository.manager.transaction(async (manager) => {
      // Convertir DTOs a entidades
      // TypeORM maneja autom√°ticamente la serializaci√≥n de JSONB
      const eventEntities = events.map(event => {
        const entity = new Event();
        entity.eventId = event.eventId; // ID √∫nico generado por el sistema
        entity.timestamp = event.timestamp; // ISO 8601 UTC
        entity.service = event.service;
        entity.message = event.message;
        entity.metadata = event.metadata || null; // JSONB - TypeORM serializa autom√°ticamente
        entity.ingestedAt = event.ingestedAt; // ISO 8601 UTC
        return entity;
      });
      
      // INSERTAR EN LOTE (mucho m√°s r√°pido que uno por uno)
      await manager.save(Event, eventEntities);
    });
    
    return { successful: events.length, failed: 0 };
  } catch (error) {
    // Si falla, todos los eventos del batch fallan
    return { successful: 0, failed: events.length };
  }
}
```

### Estructura de la Tabla:

```sql
CREATE TABLE events (
  id UUID PRIMARY KEY,
  event_id VARCHAR(20) UNIQUE NOT NULL,
  timestamp TEXT NOT NULL,  -- ISO 8601 format in UTC (e.g., '2024-01-15T10:30:00.000Z')
  service VARCHAR(100) NOT NULL,
  message TEXT NOT NULL,
  metadata JSONB,  -- Native PostgreSQL JSONB type (enables JSON queries)
  ingested_at TEXT NOT NULL,  -- ISO 8601 format in UTC
  created_at TIMESTAMPTZ DEFAULT now()  -- UTC timestamp with time zone
);

-- √çndices para optimizar consultas
CREATE INDEX idx_events_service_timestamp ON events (service, timestamp);
CREATE INDEX idx_events_service_created_at ON events (service, created_at);
CREATE INDEX idx_events_timestamp ON events (timestamp);
CREATE INDEX idx_events_created_at ON events (created_at);
CREATE INDEX idx_events_event_id ON events (event_id);
CREATE INDEX idx_events_metadata_gin ON events USING GIN (metadata);  -- GIN index for JSONB queries
```

**Notas importantes:**
- **Timezone**: Todas las fechas se almacenan en UTC. PostgreSQL est√° configurado con `timezone: 'UTC'` y el contenedor Docker usa `TZ=UTC`.
- **Metadata JSONB**: Usa el tipo JSONB nativo de PostgreSQL que permite:
  - Consultas JSON nativas: `WHERE metadata->>'userId' = '123'`
  - √çndices GIN para b√∫squedas eficientes en JSON
  - Validaci√≥n autom√°tica de JSON
  - Mejor rendimiento que almacenar JSON como texto

-- √çndice compuesto para consultas r√°pidas
CREATE INDEX idx_service_timestamp ON events(service, timestamp);
```

**¬øPor qu√© batch insert?**
- 500 inserts individuales: ~5 segundos
- 1 batch insert de 500: ~50 milisegundos
- **100x m√°s r√°pido** üöÄ

---

## üîÑ PASO 6: Manejo de Errores y Reintentos

### ¬øQu√© pasa si la base de datos falla?

**Escenario:** La base de datos est√° lenta o no responde.

```typescript
// Intento 1: Falla
await this.eventsService.batchInsert(events);  // ‚ùå Error

// Esperar 100ms (exponential backoff)
await sleep(100);

// Intento 2: Falla
await this.eventsService.batchInsert(events);  // ‚ùå Error

// Esperar 200ms
await sleep(200);

// Intento 3: Falla
await this.eventsService.batchInsert(events);  // ‚ùå Error

// Esperar 400ms
await sleep(400);

// Intento 4: √âxito ‚úÖ
await this.eventsService.batchInsert(events);  // ‚úÖ Success
```

### Exponential Backoff:

```
Intento 1: Esperar 100ms  (2^0 * 100)
Intento 2: Esperar 200ms  (2^1 * 100)
Intento 3: Esperar 400ms  (2^2 * 100)
Intento 4: Esperar 800ms (2^3 * 100)
Intento 5: Esperar 1600ms (2^4 * 100)
...
M√°ximo: 5000ms (5 segundos)
```

### Si todos los reintentos fallan:

```typescript
// Evento permanentemente fallido
this.logger.error(
  `Event ${event.eventId} permanently failed after 3 retries`,
  { eventId, service, timestamp }
);
// Se guarda en dead-letter log (no crashea el sistema)
```

**Importante:** El worker **nunca se detiene**. Contin√∫a procesando el siguiente batch.

---

## üîç PASO 7: Consulta de Eventos (GET /events)

### Ejemplo de Query:

```bash
GET /events?service=auth-service&from=2024-01-15T00:00:00Z&to=2024-01-15T23:59:59Z&limit=50&offset=0
```

### ¬øC√≥mo funciona?

**Archivo:** `src/events/services/events.service.ts` - m√©todo `queryEvents()`

```typescript
async queryEvents(queryDto: QueryEventsDto) {
  const { service, from, to, limit = 100, offset = 0 } = queryDto;
  
  // 1. CONTAR TOTAL (para paginaci√≥n)
  const total = await this.eventRepository
    .createQueryBuilder('event')
    .where('event.service = :service', { service })
    .andWhere('event.timestamp >= :from', { from })
    .andWhere('event.timestamp <= :to', { to })
    .getCount();
  
  // 2. CONSULTAR CON PAGINACI√ìN (usando √≠ndice compuesto)
  const events = await this.eventRepository
    .createQueryBuilder('event')
    .where('event.service = :service', { service })
    .andWhere('event.timestamp >= :from', { from })
    .andWhere('event.timestamp <= :to', { to })
    .orderBy('event.timestamp', 'DESC')
    .limit(limit)
    .offset(offset)
    .getMany();
  
  return { events, total, limit, offset, hasMore: offset + limit < total };
}
```

### Respuesta:

```json
{
  "events": [
    {
      "id": "evt_abc123",
      "timestamp": "2024-01-15T10:30:00Z",
      "service": "auth-service",
      "message": "User login successful",
      "metadata": { "user_id": "12345" }
    }
  ],
  "pagination": {
    "total": 1250,
    "limit": 50,
    "offset": 0,
    "has_more": true
  }
}
```

**Tiempo de consulta:** < 100ms (gracias al √≠ndice compuesto)

---

## üßπ PASO 8: Limpieza Autom√°tica (Retention)

### ¬øC√≥mo funciona?

**Archivo:** `src/retention/retention.service.ts`

```typescript
@Cron('0 2 * * *')  // Todos los d√≠as a las 2 AM
async handleCleanup() {
  // Eliminar eventos m√°s antiguos que 30 d√≠as
  const deletedCount = await this.eventsService.deleteOldEvents(30);
  this.logger.log(`Deleted ${deletedCount} old events`);
}
```

### Proceso:

```sql
-- Calcular fecha de corte (30 d√≠as atr√°s)
DELETE FROM events 
WHERE timestamp < '2023-12-16T00:00:00Z';
```

**Se ejecuta autom√°ticamente** todos los d√≠as a las 2 AM. No requiere intervenci√≥n manual.

---

## üìä Flujo Completo Visual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   1. REQUEST PATH (R√°pido)                   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cliente ‚Üí POST /events                                      ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Validaci√≥n (schema, tama√±o)                                 ‚îÇ
‚îÇ     ‚Üì (si inv√°lido ‚Üí 400 Bad Request)                       ‚îÇ
‚îÇ  Verificar buffer (si lleno ‚Üí 429 Too Many Requests)        ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Encolar en buffer (O(1))                                   ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Responder 202 Accepted (< 5ms)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             2. BACKGROUND WORKER (Resiliente)                ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cada 1 segundo:                                             ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Drenar buffer (500 eventos)                                ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Validaci√≥n profunda                                         ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Batch insert a DB (transacci√≥n)                            ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Si falla: Reintentar con exponential backoff               ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Si falla permanentemente: Dead-letter log                  ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Continuar con siguiente batch (nunca crashea)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   3. CONSULTA (R√°pida)                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Cliente ‚Üí GET /events?service=X&from=Y&to=Z                ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Query con √≠ndice (service, timestamp)                     ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Paginaci√≥n (limit, offset)                                 ‚îÇ
‚îÇ     ‚Üì                                                        ‚îÇ
‚îÇ  Responder con eventos (< 100ms)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Puntos Clave del Dise√±o

### 1. **Request Path Liviano**
- ‚úÖ No hay I/O bloqueante (no se escribe a DB)
- ‚úÖ Validaci√≥n m√≠nima y r√°pida
- ‚úÖ Respuesta en < 5ms

### 2. **Separaci√≥n de Responsabilidades**
- ‚úÖ Request path: Recibir y encolar
- ‚úÖ Worker: Procesar y persistir
- ‚úÖ Nunca se mezclan

### 3. **Resiliencia**
- ‚úÖ Eventos inv√°lidos: Rechazados en el borde (400)
- ‚úÖ Buffer lleno: Backpressure (429/503)
- ‚úÖ DB lenta/fallando: Exponential backoff + dead-letter
- ‚úÖ Sistema nunca crashea

### 4. **Alto Rendimiento**
- ‚úÖ Batch inserts (100x m√°s r√°pido)
- ‚úÖ √çndices compuestos (consultas r√°pidas)
- ‚úÖ Buffer en memoria (O(1) append)

---

## üìà M√©tricas y Monitoreo

### Health Check Global: `GET /health`

```json
{
  "message": "SERVER_IS_READY"
}
```

### Health Checks Espec√≠ficos: `GET /health/*`

#### Buffer: `GET /health/buffer`
```json
{
  "status": "healthy",
  "buffer": {
    "size": 1250,
    "capacity": 10000,
    "utilization_percent": "12.50"
  },
  "metrics": {
    "total_enqueued": 50000,
    "total_dropped": 0,
    "drop_rate_percent": "0.00",
    "throughput_events_per_second": 83.33
  }
}
```

#### Database: `GET /health/database`
```json
{
  "status": "healthy",
  "database": "connected",
  "circuitBreaker": {
    "state": "CLOSED",
    "failures": 0,
    "successes": 1000,
    "lastFailureTime": null
  }
}
```

#### Business Metrics: `GET /health/business`
```json
{
  "totalEvents": 123456,
  "eventsByService": {
    "user-service": 50000,
    "auth-service": 30000,
    "payment-service": 20000
  },
  "eventsLast24Hours": 5000,
  "eventsLastHour": 250,
  "averageEventsPerMinute": 3.47,
  "topServices": [
    { "service": "user-service", "count": 50000 },
    { "service": "auth-service", "count": 30000 }
  ],
  "eventsByHour": [
    { "hour": "2024-01-15 10:00", "count": 150 },
    { "hour": "2024-01-15 11:00", "count": 200 }
  ]
}
```

#### Detailed Health: `GET /health/detailed`
```json
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "server": { "status": "ready", "message": "SERVER_IS_READY" },
  "database": { "status": "healthy", "database": "connected" },
  "buffer": { "status": "healthy", "buffer": {...} },
  "circuitBreaker": { "state": "CLOSED", ... },
  "business": { "totalEvents": 123456, ... }
}
```

### M√©tricas del Buffer: `GET /metrics`

```json
{
  "status": "healthy",
  "buffer_size": 1250,
  "buffer_capacity": 10000,
  "buffer_utilization_percent": "12.50",
  "metrics": {
    "total_enqueued": 50000,
    "total_dropped": 0,
    "drop_rate_percent": "0.00",
    "throughput_events_per_second": 83.33
  },
  "last_enqueue_time": "2024-01-15T10:30:00.123Z",
  "last_drain_time": "2024-01-15T10:29:55.456Z",
  "uptime_seconds": 3600
}
```

Esto te permite monitorear:
- Cu√°ntos eventos est√°n esperando en el buffer
- Si el buffer se est√° llenando (riesgo de backpressure)
- Cu√°ntos eventos se han procesado
- Estado detallado del buffer y m√©tricas de rendimiento
- Estado del circuit breaker
- M√©tricas de negocio (eventos por servicio, tendencias)

---

## üîß Configuraci√≥n

Todo es configurable via variables de entorno (todas son REQUERIDAS):

```env
# Server
PORT=3000
HOST=localhost
NODE_ENV=development

# Database (PostgreSQL)
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=admin
DB_PASSWORD=admin
DB_DATABASE=aurore_events
DB_SYNCHRONIZE=true
DB_LOGGING=false
DB_POOL_MAX=20

# Buffer
BUFFER_MAX_SIZE=50000      # Capacidad del buffer
CHECKPOINT_INTERVAL_MS=5000

# Batch Worker
BATCH_SIZE=5000            # Eventos por batch
DRAIN_INTERVAL=1000        # Intervalo de procesamiento (ms)
MAX_RETRIES=3              # Reintentos m√°ximos

# Retention
RETENTION_DAYS=30          # D√≠as de retenci√≥n
RETENTION_CRON_SCHEDULE=0 2 * * *

# Rate Limiting
THROTTLE_TTL_MS=60000
THROTTLE_GLOBAL_LIMIT=300000
THROTTLE_IP_LIMIT=10000
THROTTLE_QUERY_LIMIT=200
THROTTLE_HEALTH_LIMIT=60

# Circuit Breaker
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_SUCCESS_THRESHOLD=2
CIRCUIT_BREAKER_TIMEOUT_MS=30000

# Query
DEFAULT_QUERY_LIMIT=100
MAX_QUERY_LIMIT=1000
MAX_QUERY_TIME_RANGE_DAYS=30
```

Ver `env.example` para la lista completa de variables requeridas.

---

## ‚úÖ Resumen

1. **Evento llega** ‚Üí Validaci√≥n r√°pida ‚Üí Encolado en buffer ‚Üí Respuesta 202
2. **Worker procesa** ‚Üí Drena buffer ‚Üí Valida ‚Üí Inserta en batch ‚Üí Reintenta si falla
3. **Consulta** ‚Üí Usa √≠ndice ‚Üí Respuesta r√°pida con paginaci√≥n
4. **Limpieza** ‚Üí Autom√°tica cada d√≠a a las 2 AM

**Todo funciona de forma as√≠ncrona, resiliente y sin bloquear el request path.** üöÄ

